{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for data analysis - 2025\n",
    "**Arthur Leblois & Nicolas P. Rougier**, Institute of Neurodegenerative Diseases (IMN), Bordeaux, France.  **Slim Karkar, Amélie Aussel & Elena Nicollin**, Université de Bordeaux \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../figures/pixar.jpg\">\n",
    "\n",
    "## Sort the birds!\n",
    "\n",
    "The goal of this project is to sort (automatically) audio files that correspond to the recording of adult or juvenile songbirds. If you listen to the audio files, you will hear that the sound is quite different between an adult (song) and a juvenile (babbling). This means we can directly process the audio files in order to decide if it corresponds to an adult or a juvenile: the goal is thus to write a function `songsort(\"./some-path/\")` that will automatically sort all the files present in `some-path` and label them accordingly.\n",
    "\n",
    "However, to do so, we'll need to manipulate a lot of different notions (such as resampling, filtering, enveloppe, auto-correlation, fit) and to check our implementation is correct. So let's start with a sample adult and juvenile audio file.\n",
    "\n",
    "\n",
    "**Content**\n",
    "\n",
    "* [0. Downloading the data](#0.-Downloading-the-data)\n",
    "* [1. Configuration of the notebook](#1.-Configuration-of-the-notebook)\n",
    "* [2. Loading libraries](#2.-Loading-libraries)\n",
    "* [3. Loading data](#3.-Loading-data)\n",
    "* [4. Visualizing data](#4.-Visualizing-data)\n",
    "* [5. Denoising the signal](#5.-Denoising-the-signal)\n",
    "* [6. Smoothing the signal](#6.-Smoothing-the-signal)\n",
    "* [7. Resampling & Auto-correlation](#7.-Resampling-&-Auto-correlation)\n",
    "* [8. Wrap-up](#8.-Wrap-up)\n",
    "* [9. Batch processing](#9.-Batch-processing)\n",
    "* [10. Fit the signal](#10.-Fit-the-signal)\n",
    "* [11. Processing files](#11.-Processing-files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Downloading the data\n",
    "\n",
    "**Data** is available on [figshare](https://doi.org/10.6084/m9.figshare.14611791.v1).\n",
    "\n",
    "Once downloaded, you can unzip it in the project directory: this means the new folder `birdsong_data` (which contains a folder `PythonProject_records` containing all the data files) should be **in the same location** as where you have this notebook saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration of the notebook\n",
    "\n",
    "We need first to setup a few options in the notebook such as to have inline plots as well as a nicer output on OSX.  \n",
    "There is not much to understand here, these options are documented in the [Jupyter notebook documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html).\n",
    "\n",
    "Make sure you run this cell before moving on to the next parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask jupyter to display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# OSX specific (for a nicer display on \"retina\" screen)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "### 2. Loading libraries\n",
    "Next step is to load all the Python libraries that will be needed for processing & displaying our data. Namely:\n",
    "* [NumPy](https://www.numpy.org/) which is the fundamental package for scientific computing with Python.\n",
    "* [SciPy](https://www.scipy.org/) which is a Python-based ecosystem of open-source software for mathematics, science, and engineering.\n",
    "* [Matplotlib](https://matplotlib.org/) which is a plotting library that produces publication quality figures. \n",
    "* [IPython](https://ipython.org/) that provides a rich architecture for interactive computing\n",
    "\n",
    "Note that during this course, we'll only use a small part of IPython (to play sound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical package (we are importing numpy using the alias np)\n",
    "import numpy as np\n",
    "\n",
    "# Signal processing (we need to import the submodule \"signal\" from \"scipy\", no alias)\n",
    "import scipy.signal\n",
    "\n",
    "# TODO:\n",
    "# Package to display figures (we need to import the submodule \"pyplot\" from \"matplotlib\" using the alias plt)\n",
    "# ...\n",
    "\n",
    "# TODO:\n",
    "# Package to read wav files (we need to import the submodule \"wavfile\" from the submodule \"io\" from \"scipy\")\n",
    "# ...\n",
    "\n",
    "# TODO: write this\n",
    "# Package to display widgets inside the notebook (we need to import the submodules \"Audio\" and \"display\" from \"IPython.display\")\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading data\n",
    "\n",
    "The first thing to do is to load our data from a local file that must be present in your `data` directory. To do that, we'll write a `get_local_data` function that reads a `wav` filename (`wav` file are sound files encoded in the [Waveform audio file format](https://fr.wikipedia.org/wiki/Waveform_Audio_File_Format)) using a dedicated function of scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename = None):\n",
    "    rate, signal = wavfile.read(filename)\n",
    "    return rate, signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load some data and check for their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./birdsong_data/PythonProject_records/record-001.wav\"\n",
    "\n",
    "# TODO: \n",
    "# write the code here that uses the function of the above cell to get the sampling rate (rate) of the audio file and the signal (S) itself\n",
    "# ...\n",
    "\n",
    "print(\"Frequency: {:.1f}kHz\".format(rate/1000))\n",
    "print(\"Length: {}\".format(len(S)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has been read and we know that the sampling frequency is 44.1 kHz and the number of data points is 530833.  \n",
    "From this, we can compute the time duration of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Compute the duration of the signal\n",
    "# ...\n",
    "print(\"Duration: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Visualizing data\n",
    "\n",
    "We can now display our data using the `plot` function from matplotlib. To do that, we need to have the X and Y coordinates of points. The Y data is given by the `signal` but we need to generate the corresponding X data. Knowing the duration and the number of Y data, we can write X using the numpy [linspace(start,stop,num)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Use linspace from numpy (np.linspace) to generate the time vector T\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to create a new figure and plot our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see only a subpart of the signal, you can limit explicitely the x range using the [xlim(xmin,xmax)](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlim.html) function, and the y range with the [ylim(ymin,ymax)](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylim.html) function, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S)\n",
    "plt.xlim(1.95,2.0)\n",
    "plt.ylim(-5000,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, and knowing our data is an audio file, we can benefit from a better visualization using the [specgram](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.specgram.html) function of matplotlib that is dedicated to the visualization of spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.specgram(S, Fs=rate, cmap=\"magma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last, but not least, using the IPython library, we can display a widget in order to play the audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display a widget to play the sound\n",
    "display(Audio(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Denoising the signal\n",
    "\n",
    "Before going any further in our processing, we need to remove noise originating from recording default and ambient noise. We'll use a [high-pass filter (HPF)](https://en.wikipedia.org/wiki/High-pass_filter) that is  *an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency* (Wikipedia). To do that, we first need to build a filter among [those available](https://docs.scipy.org/doc/scipy/reference/signal.html) and we apply the filter to our signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Create a highpass filter in the format [b,a] at a cut-off frequency of 500Hz\n",
    "# Hint: read the scipy.signal documentation and the lesson notebook on signal analysis\n",
    "# ...\n",
    "\n",
    "# Apply the filter to the original signal to obtain your new filtered signal (S_)\n",
    "# ...\n",
    "\n",
    "# Calculate the difference (D) between the original and the filtered signals\n",
    "# ...\n",
    "\n",
    "# and plot the filtered signal and the calculated difference\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S_)\n",
    "plt.plot(T, D)\n",
    "\n",
    "# ! Keep in mind we will be using the *filtered* signal S_ from now on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use the specgram function again to visualize the filtered signal\n",
    "plt.figure(figsize=(16,3))\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen to a comparison between the original (noisy) and the filtered (denoised) signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy version\n",
    "display(Audio(S, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoised signal\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Smoothing the signal\n",
    "\n",
    "We want to smooth the signal by averaging each value with neighboring values, using a Gaussian window. To do that, we first need to define the neighboring range (in seconds). Then we define a gaussian signal over this range and centered in the middle and finally we compute the smooth signal (enveloppe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of the time window over which to smooth the signal\n",
    "dt = 0.025\n",
    "trange = int(dt*rate)\n",
    "\n",
    "# Standard deviation of the gaussian\n",
    "sigma = trange/4\n",
    "\n",
    "# Actual temporal window over which to compute the Gaussian\n",
    "window = np.arange(-trange//2,trange//2)\n",
    "\n",
    "# Gaussian function over window and standard deviation sigma\n",
    "gaussian = np.exp(-(window/sigma)**2)\n",
    "gaussian = gaussian/np.sum(gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize our smoothing window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the Gaussian \n",
    "plt.plot(window/rate, gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compte the envelope using the  convolution product that is mathematically defined as:\n",
    "$(f * g)(t) \\triangleq\\ \\int_{-\\infty}^\\infty f(t-\\tau) g(\\tau)\\, d\\tau$\n",
    "\n",
    "The illustration below (from the [Wikipedia page on convolution](https://en.wikipedia.org/wiki/Convolution)) shows how it is computed:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use the numpy convolution function to obtain the smoothed signal (E)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did things properly, the signal and its enveloppe variations should be aligned.  \n",
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the signal before and after convolution\n",
    "T = np.linspace(0, duration, len(S_))\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.xlim(1,3)\n",
    "\n",
    "# signal before convolution:\n",
    "plt.plot(T, abs(S_), alpha=0.5)\n",
    "\n",
    "# TODO\n",
    "# convoluted signal:\n",
    "# ...\n",
    "\n",
    "# TODO\n",
    "# Display the spectrograms of each signal\n",
    "# signal before convolution:\n",
    "# ...\n",
    "\n",
    "# convoluted signal:\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Resampling & Auto-correlation\n",
    "\n",
    "We can now compute the auto-correlation of the signal, that is, the correlation of the signal with itself. Howewer, since the signal is quite large, we'll first extract only a few points linearly spread over the signal and then compute the auto-correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the signal with different interval sizes\n",
    "E1 = E[::1]\n",
    "E10 = E[::10]\n",
    "E100 = E[::100]\n",
    "E1000 = E[::1000]\n",
    "E10000 = E[::10000]\n",
    "# the size of each sampling obtained:\n",
    "print(len(E1),len(E10), len(E100), len(E1000), len(E10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing what the signal looks like when sampling every 100 points, every 10000 points.\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(np.linspace(0,duration,len(E100)), E100)\n",
    "plt.plot(np.linspace(0,duration,len(E10000)), E10000)\n",
    "\n",
    "# you can try visualizing the other extractions too if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we decide to keep the signal with the sampling interval of 100\n",
    "E100 = E[::100]\n",
    "C = np.correlate(E100, E100, mode='same') / (E100**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An we can now visualize the result in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T = .5*np.linspace(-len(S)/rate, +len(S)/rate , len(C))\n",
    "plt.plot(T, C)\n",
    "plt.xlim(-0.5,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a narrow peak in the center, and two smaller peaks around it.\n",
    "\n",
    "Let's see what happens now for a juvenile bird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Wrap-up\n",
    "\n",
    "It's now time to write a function that, given a wav file, computes the auto-correlation. To do this, we just need to wrap-up what we've written so far and choose the relevant arguments to give when we call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def autocorr(data, dt=0.025):\n",
    "    \"\"\"\n",
    "    Compute the auto-correlation of an audio signal using a Gaussian\n",
    "    smoothing window (with duration dt)\n",
    "    \n",
    "    data: (rate, signal)\n",
    "        data is an audio signal made of 2 variables. First one (rate)\n",
    "        is the sampling frequency of the signal and second one (signal)\n",
    "        is the actual signal.\n",
    "    \n",
    "    dt: float\n",
    "        Duration of the time window (Gaussian) to smooth the signal. \n",
    "        Default value is 250 milliseconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ...\n",
    "    return T, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Batch processing\n",
    "\n",
    "So far, we've been working with a unique file whose name was known to us. We would like now to process all the wav files in the data directory. This means we need to first find them and then process them. To do that, we'll use the [glob](https://docs.python.org/3/library/glob.html) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(\"./birdsong_data/PythonProject_records/*.wav\")[4:8] # can you understand what this line does?\n",
    "\n",
    "# Let's plot some data\n",
    "ax = None\n",
    "plt.figure(figsize=(16,4))\n",
    "for index, filename in enumerate(files):\n",
    "    T, C = autocorr(get_data(filename))\n",
    "    ax = plt.subplot(1, 4, 1+index, aspect=1, sharey=ax)\n",
    "    ax.plot(T, C)\n",
    "    ax.set_xlim(-0.5,0.5)\n",
    "    ax.set_title(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Fit the signal\n",
    "\n",
    "It seems the auto-correlation of adult birds songs is more complex than the auto-correlation of juveniles songs. More precisely, the juveniles look like a kind of Gaussian while the adults look like a periodic Gaussian. Consequently, if we try to fit juveniles auto-correlation with a Gaussian function, the difference between the fit and the signal would be relatively small, while for adults it should be much bigger. Let's just try that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [curve_fit](https://scipy.github.io/devdocs/generated/scipy.optimize.curve_fit.html) function from [scipy.optimize](https://scipy.github.io/devdocs/optimize.html) that, given a parameterized function, will search for the best combination of parameter. So let's write a Gaussian function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Gaussian we want to use for fitting\n",
    "def exponential(X, a, b, c):\n",
    "    return a*np.exp(-((X/b)**2)) + c\n",
    "\n",
    "filename = \"./birdsong_data/PythonProject_records/record-003.wav\" #juvenile bird\n",
    "\n",
    "# TODO\n",
    "# We get the auto-correlation\n",
    "# ...\n",
    "\n",
    "# We extract the values of the auto-correlation between -0.5 and 0.5\n",
    "# ...\n",
    "\n",
    "# We fit the curve\n",
    "# ...\n",
    "\n",
    "# We display the result\n",
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "plt.plot(T, C, color='#999999')\n",
    "plt.plot(T, G, color='k', lw=2)\n",
    "plt.title(\"Original signal and fitted Gaussian\")\n",
    "\n",
    "# We compute the score\n",
    "# ...\n",
    "\n",
    "# We print the score\n",
    "print(\"Score: {0}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap everything into a score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def score(filename, tmin=-0.5, tmax=0.5):\n",
    "    # ...\n",
    "    return score\n",
    "    \n",
    "files = glob.glob(\"./birdsong_data/PythonProject_records/*.wav\")[:10] #testing on few files\n",
    "for filename in files:\n",
    "    print(\"{0} : score={1}\".format(filename, score(filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Processing files\n",
    "\n",
    "We can now use our function to score each `wav` file in the data directory.\n",
    "**Be careful before running the code, it will take some time to compute!**.  \n",
    "We'll use the [tqdm package](https://pypi.org/project/tqdm/) to show progress while computing individual scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook\n",
    "files = glob.glob(\"./birdsong_data/PythonProject_records/*.wav\")\n",
    "\n",
    "scores = []\n",
    "for filename in files:\n",
    "    scores.append(score(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our hypothesis regarding the fitting of the Gaussian for adults and juveniles is right, we should have two groups of score, one low and one high. Let's plot a histogram to check visually if it is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scores, bins=50)\n",
    "plt.title(\"Histogram of Gaussian-fit score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see on the graph above that there are two different groups of score. Visually, the frontiers between the two groups seems to be a score of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(scores)\n",
    "print( (scores < 20).sum(), (20 <= scores).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
