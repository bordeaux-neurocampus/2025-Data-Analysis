{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI mini project - Time_Frequency analysis for resting state maps\n",
    "In this project, we will work on fMRI data from the  Amsterdam Open MRI Collection (AOMIC).\n",
    "\n",
    "The AOMIC dataset gathers MRI data from more than a thousand individuals obtained on a 3 Tesla imager. For each subject we can access the T1-weighted images ( anatomical image), the diffusion-weighted images ( white-matter tracts)  and fMRI sequences (task-based and resting states). The dataset gives access to both raw and preprocessed (derivative) data. The description of the data acquisition and processing is available here : \n",
    "\n",
    "**Snoek, L., van der Miesen, M. M., Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., & Scholte, H. S. (2021). The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses. Scientific data, 8(1), 1-23.**\n",
    "\n",
    "All data are publicly available for downloads using AWS s3 buckets s3://openneuro.org/. The projects will use Jupyter Notebook with the following library : numpy, scipy,  scikit-learn; nilearn.\n",
    "\n",
    "We will use time-frequency analysis to propose connectivity map in resting-state and compared with the RSN proposed in the paper :   **Smith, SM, Fox, PT, Miller, KL, Glahn, DC, Fox, PM, Mackay, CE, Filippini, N, Watkins, KE, Toro, R, Laird, AR, Beckmann, CF (2009). Correspondence of the brain's functional architecture during activation and rest. Proc Natl Acad Sci U S A, 106, 31:13040-5.**\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Installing required libraries\n",
    " \n",
    "%matplotlib inline\n",
    "!pip install nilearn\n",
    "!pip install datalad[full]\n",
    "#!pip install git-annex # might be needed\n",
    "import os\n",
    "import nilearn \n",
    "import re \n",
    "import numpy as np\n",
    "from nilearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the S3 bucket \"openneuro.org\"  all links available in https://github.com/OpenNeuroDatasets/dsxxxx. The file and directory strucure corresponds to the path of the object in a [BIDS](https://bids-specification.readthedocs.io/en/stable/index.html) standard.\n",
    "\n",
    "Find the dataset for  PIOP1 cohort (it starts with dsXXX....)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad clone https://github.com/OpenNeuroDatasets/d.....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIOP1 cohort is in directory dsxxx \n",
    "\n",
    "preprocessed data are in /derivatives folder\n",
    "\n",
    "let's get all the task working memory fmri files for  individual sub-001\n",
    "\n",
    "we are looking for 'task-restingstate' in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!datalad clone https://github.com/OpenNeuroDatasets/ds002790.git\n",
    "import glob\n",
    "dir_nii=...\n",
    "task_list=glob.glob(dir_nii+...)\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through all files with nii.gz endings\n",
    "import pandas as pd\n",
    "nii_task=np.array([x.endswith('nii.gz') for x in task_list]) \n",
    "nii_files=np.asarray(task_list)[nii_task]\n",
    "nii_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now list all the nii.gz files\n",
    "\n",
    "we  can use 'endwith' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Use Panda library to select our files\n",
    "\n",
    "import pandas as pd\n",
    "dir_nii=\"...\n",
    "task_list=os.listdir(dir_nii)\n",
    "\n",
    "nii_task=np.array([x.endswith(....) for x in task_list]) \n",
    "nii_files=np.asarray(task_list)[nii_task]\n",
    "nii_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the file for preprocessed  frmi volumes in MNI space and dowload it with datalad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ds002790 ; datalad get ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_bold=...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "\n",
    "img_path=dir_nii+\"/\"+resting_bold\n",
    "img_path\n",
    "img= ... # load your image with image.load_img\n",
    "print(img.get_data().shape) # check image dimensions with shape\n",
    "# launch interactive 3d view with view_img function\n",
    "plotting.view_img(image.index_img(img, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we going to compute the mean (average) image usinng numpy\n",
    "# you need to import the numpy library\n",
    "import ...\n",
    "# find nilearn image function to compute average 3d volume of a fMRI sequence volume\n",
    "# compute average image using image library\n",
    "mean_img= ...\n",
    "# always check the dimension of the data \n",
    "print(.... ) \n",
    "# use the  triplanar interactive view of nilearn\n",
    "# to explore the average 3d volume\n",
    "... mean_img ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to extract all the data and plot them separately either as 2d image eaither aas time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# extract 4D array from nilear image object\n",
    "volume= ....\n",
    "# check the dimension of the data \n",
    "print (volume.shape)\n",
    "# eextract one slice (2D image)\n",
    "flat_slice=volume..... \n",
    "# check thye size\n",
    "print (flat_slice.shape)\n",
    "# use matplotlib imshow to plot the slice  \n",
    "plt.imshow(flat_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the time serie for one voxel \n",
    "ts=volume ....\n",
    "# in the AOMICS website find repeat tim RT RT : time in sec between 2 image in [s]  \n",
    "dt=...\n",
    "# make a vector of slice times in [s]  \n",
    "time_vec= ...# vector \n",
    "print(time_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "# plot the normalaized time serie\n",
    "plt.plot(... , label='bold signal at'+np.array2string(np.array([30,35,30])), linewidth=0.5)\n",
    "plt.ylabel('bold signal')\n",
    "plt.title('bold signal for 1 voxel')\n",
    "plt.xlabel('time in [s]')\n",
    "# Add legend\n",
    "plt.legend()\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "# Display plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the AOMICS website find which file is the segmentation file (the brain regions) and dowload it with datalad.\n",
    "\n",
    "We will use  the aparc + aseg segmentation image\n",
    "\n",
    "The regions  labels are detailed here :\n",
    " https://github.com/freesurfer/freesurfer/blob/dev/distribution/FreeSurferColorLUT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ds002790 ; datalad get ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = ...  \n",
    "file_path=dir_nii+\"/\"+file_key\n",
    "img_seg=image.load_img(file_path)\n",
    "print(np.asanyarray(img_seg.dataobj).shape)\n",
    "plotting.plot_roi(img_seg, threshold=1, cmap=plt.cm.prism)\n",
    "plotting.view_img(img_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "import nibabel as nb\n",
    "img_segbool=np.asanyarray(img_seg.dataobj)#\n",
    "img_segbool[:]=0\n",
    "for i_seg in [...]: #find one or several  region of interest as the seed for Default mode network\n",
    "    mask=np.where(img_array==i_seg)\n",
    "    img_segbool[mask]=10\n",
    "\n",
    "mask\n",
    "#img_segbool[0:,0:,0:]=0\n",
    "print(np.sum(img_segbool)/10)\n",
    "nii_img_seg=nb.Nifti1Image(img_segbool, affine=img_seg.affine)\n",
    "plotting.plot_roi(nii_img_seg, threshold=1, cmap=plt.cm.prism)\n",
    "plotting.view_img(nii_img_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will use the segmentation to create a mask of region to extract all the time series from one region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kj4PnXzns37A",
    "outputId": "f5d5497e-ac00-485f-f90a-b1b1a759f75e"
   },
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "import nibabel as nb\n",
    "# extract the segmentation volume in a np.array \n",
    "img_segbool=np.array(..)\n",
    "# always check the size\n",
    "print(np.sum(img_segbool))\n",
    "# with np.where find the voxels of the region of interest \n",
    "# that will bu used as seed for Default Mode Network\n",
    "mask1=np.where(...)\n",
    "# now set all background to 0\n",
    "img_segbool....=0\n",
    "#  and set the voxels from the mask to 10\n",
    "img_segbool...=10\n",
    "\n",
    "\n",
    "#always check the size is right\n",
    "img_segbool.shape\n",
    "# count hozw many voxels in the region with np.sum\n",
    "np.sum(...)\n",
    "#  find how to make a proper nii volume from img_segbool \n",
    "#  using  Nifti1Image function and the original img_seg volume \n",
    "nii_img_seg=nb.Nifti1Image(....)\n",
    "# use the interactive region viewer to check your segmentation \n",
    ".....\n",
    "# find how to use apply_mask to retreive the timeseries of the selected region\n",
    "# using the original nii volume img and the region volume nii_img_seg\n",
    "masked_data = ....\n",
    "\n",
    "# check masked_data shape is (timepoints, voxels).\n",
    "masked_data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "X2GIaFPGs9Mi",
    "outputId": "3abfefb9-e2bf-4819-b481-9cc7def1f5bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# And now plot two time series\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(masked_data[:, :2])\n",
    "plt.xlabel('Time [TRs]', fontsize=16)\n",
    "plt.ylabel('Intensity', fontsize=16)\n",
    "#plt.xlim(0, 150)\n",
    "plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to process the time serie. \n",
    "First we need to load the scipy libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft,fftfreq\n",
    "from scipy.fftpack import fftshift\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step  is removing complex signal drift\n",
    "For that we are fititng three degree polygone curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vboU2YtptAjZ"
   },
   "outputs": [],
   "source": [
    "### removing complex signal drift \n",
    "#choose a time serie as example : \n",
    "ts = ...\n",
    "# a / fit a 4 degree polynome -- or a low frequency cosine\n",
    "# for a polynome\n",
    "# find a0, a, b, c, d that fit the signal y= a0 + ax + bx² +cx³ +dx⁴\n",
    "# you can use the code used in the filtering exercice \n",
    "# with optimize.curve_fit and a test_func \n",
    "# or use numpy.polyfit\n",
    "# for low frequency cosine, use very low (<0.01) frequecy\n",
    "#for starting parameters optimize.curve_fit  \n",
    "\n",
    "drift = ....\n",
    "\n",
    "# b/ remove the fitted drift from the signa\n",
    "yf=ts-drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the AOMICS website find repeat tim RT RT : time in sec between 2 image in [s]  \n",
    "dt=...\n",
    "# make a vector of slice times in [s]  \n",
    "time_vec= ...# vector \n",
    "print(time_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the whole process\n",
    "t = time_vec\n",
    "y=ts\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "# plot signal and the fitted drift\n",
    "ax2=plt.subplot(411)\n",
    "plt.plot(t, y, 'b-', label='signal')\n",
    "plt.plot(t,drift, 'g--', label='drift')\n",
    "plt.ylabel('bold signal')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# plot  sprectrogram for original signal \n",
    "freqs, times, spectro = spectrogram( y,fs=1/dt, nperseg=3)\n",
    "plt.subplot(412, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.legend()\n",
    "\n",
    "# plot old and new signal (centerd on the mean)\n",
    "plt.subplot(413, sharex=ax2)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, y-y.mean(), label='old bold signal', linewidth=0.5)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, yf-yf.mean(), label='new voxel bold signal', linewidth=2)\n",
    "plt.legend()\n",
    "\n",
    "# plot  sprectrogram for new signal \n",
    "freqs, times, spectro = spectrogram( yf,fs=1/dt, nperseg=3)\n",
    "plt.subplot(414, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.xlabel('t [sec]')\n",
    "plt.legend()\n",
    "\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a high pass filter with the code use in the filtering exercice \n",
    "# find the value in the reference article\n",
    "fc = ... # desired cutoff frequency of the filter, in Hz.\n",
    "....\n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the original signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "...\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a low pass filter  with the code use in the filtering exercice\n",
    "# find the value in the reference article\n",
    "fc = ...\n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the original signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "...\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write a function that implemets all the steps\n",
    "# and propose a measure of correlation based ond frequecy spectrum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend to cross-region analysis using the seed methods"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
