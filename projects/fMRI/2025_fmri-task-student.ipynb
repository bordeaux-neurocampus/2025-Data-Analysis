{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef2a38a",
   "metadata": {},
   "source": [
    "### fMRI mini project - HDRf fit for memory task\n",
    "In this project, we will work on fMRI data from the  Amsterdam Open MRI Collection (AOMIC).\n",
    "\n",
    "The AOMIC dataset gathers MRI data from more than a thousand individuals obtained on a 3 Tesla imager. For each subject we can access the T1-weighted images ( anatomical image), the diffusion-weighted images ( white-matter tracts)  and fMRI sequences (task-based and resting states). The dataset gives access to both raw and preprocessed (derivative) data. The description of the data acquisition and processing is available here : \n",
    "\n",
    "Snoek, L., van der Miesen, M. M., Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., & Scholte, H. S. (2021). The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses. Scientific data, 8(1), 1-23.\n",
    "\n",
    "All data are publicly available for downloads using AWS s3 buckets s3://openneuro.org/. The projects will use Jupyter Notebook with the following library : numpy, scipy,  scikit-learn; nilearn.\n",
    "\n",
    "We will study HRF variation for various task and use convolution tools to fine tune HRF models in different activation task using following model : https://github.com/andrewjahn/AndysBrainBook/blob/master/docs/SPM/SPM_Short_Course/SPM_Statistics/SPM_03_Stats_HRF_Overview.rst \n",
    "\n",
    "The AOMIC dataset is avalable for download as S3 bucket. We will use the boto3 package to search and download the elemts we need.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n-njthbSC4Jm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-njthbSC4Jm",
    "outputId": "8d4762a2-59a4-4615-c647-b5c6eb18a2fd"
   },
   "outputs": [],
   "source": [
    "# using pip command, install datalad and git-annex \n",
    "!pip ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e7d8a",
   "metadata": {
    "id": "2a8e7d8a"
   },
   "source": [
    "From the S3 bucket \"openneuro.org\"  all links available in https://github.com/OpenNeuroDatasets/dsxxxx. The file and directory strucure corresponds to the path of the object in a [BIDS](https://bids-specification.readthedocs.io/en/stable/index.html) standard.\n",
    "\n",
    "Find and download the dataset for  PIOP1 cohort (it starts with dsXXX....)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a439e",
   "metadata": {
    "id": "3e5a439e"
   },
   "outputs": [],
   "source": [
    "\n",
    "!datalad clone https://github.com/OpenNeuroDatasets/ds....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e67559",
   "metadata": {},
   "source": [
    "\n",
    "PIOP1 cohort is in directory dsxxx \n",
    "\n",
    "preprocessed data are in /derivatives folder\n",
    "\n",
    "let's get all the task working memory fmri files for  individual sub-001\n",
    "\n",
    "we are looking for  fmri files for  individual sub-001 that matches  \"task-workingmemory\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2deb0",
   "metadata": {
    "id": "f0d2deb0"
   },
   "outputs": [],
   "source": [
    "# Loading Resting State images found on AOMIC for ind 0001\n",
    "##########################################################\n",
    "\n",
    "# 1 - Filter the data to include task memory only in the preprocessed fmri data\n",
    "dir_nii=...\n",
    "task_list=glob.glob(dir_nii+...)\n",
    "task_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90208649",
   "metadata": {
    "id": "90208649"
   },
   "source": [
    "now list all the nifti images  files, we  can use 'endwith' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d653a3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "2d653a3e",
    "outputId": "1ee4762b-1437-4e5c-ef60-947b675996fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nii_task=np.array([x.endswith(...) for x in task_list]) \n",
    "nii_files=np.asarray(task_list)[...]\n",
    "nii_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SqNC_7YeG9L4",
   "metadata": {
    "id": "SqNC_7YeG9L4"
   },
   "source": [
    "select the name for preprocessed workingmemory frmi volumes in MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac10995",
   "metadata": {
    "id": "7ac10995"
   },
   "outputs": [],
   "source": [
    "file_name = nii_files[...]  # choose the file you want in nii_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2c38f",
   "metadata": {
    "id": "9fa2c38f"
   },
   "outputs": [],
   "source": [
    "# use datalad to actually dowload it\n",
    "\n",
    "!cd ds002785; datalad get ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaff540",
   "metadata": {},
   "source": [
    "Now we do the same to find the event .tsv file for task working memory the same individual.\n",
    "you can look for file name that match \"events\" or \"tsv\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w5cQ1vXAJx2w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5cQ1vXAJx2w",
    "outputId": "1167f84c-f1f5-4427-eeca-077b8f8fbb28"
   },
   "outputs": [],
   "source": [
    "event_list=glob.glob(dir_nii+...)\n",
    "event_list=... \n",
    "# and print the file list\n",
    "print (event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hbz1AM6HKGZf",
   "metadata": {
    "id": "hbz1AM6HKGZf"
   },
   "outputs": [],
   "source": [
    "# there should be only one file for working memory\n",
    "# use datalad to actually dowload it\n",
    "!cd ds002785; datalad get ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RydvzJhtKfqg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RydvzJhtKfqg",
    "outputId": "7a1cee01-327b-4e2d-d028-281974c26145",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use panda csv reader to load csv file and print it\n",
    "pd_events=...\n",
    "pd_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nwYcqJhwHqKN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "nwYcqJhwHqKN",
    "outputId": "8a63a236-a45a-4ef7-9e93-58d00cc2c51f"
   },
   "outputs": [],
   "source": [
    "# if needed install nilearn package with pip\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe63396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fe63396",
    "outputId": "1eaf655e-351a-4dde-f29f-4eb965899e0d"
   },
   "outputs": [],
   "source": [
    "# import the nilearn image library \n",
    "....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb04bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10bb04bb",
    "outputId": "9d995170-453c-4c77-c8c1-67ccb53cc641",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  read  the tasmemory image volume with nilear image library\n",
    "img=  ...\n",
    "#  always check and print the dimension of the data\n",
    "print(img .... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e44f6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "62e44f6c",
    "outputId": "b0489a64-0dc0-4e39-cacf-1895612d20e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we going to compute the mean (average) image using numpy\n",
    "# you need to import the numpy library\n",
    "import ...\n",
    "# find nilearn image function to compute average 3d volume of a fMRI sequence volume\n",
    "# compute average image using image library\n",
    "mean_img= ...\n",
    "# always check the dimension of the data \n",
    "print(.... ) \n",
    "# use the  triplanar interactive view of nilearn\n",
    "# to explore the average 3d volume\n",
    "... mean_img ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67316d1e",
   "metadata": {},
   "source": [
    "Now we are going to extract all the data and plot them separately either as 2d image either as time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519c006",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "a519c006",
    "outputId": "f81bf71e-0631-49a0-9a94-1e776ac88c0e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# extract 4D array from nilear image object\n",
    "volume= ....\n",
    "# check the dimension of the data \n",
    "print (volume.shape)\n",
    "# extract one slice (2D image)\n",
    "flat_slice=volume..... \n",
    "# check thye size\n",
    "print (flat_slice.shape)\n",
    "# use matplotlib imshow to plot the slice  \n",
    "plt.imshow(flat_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35f375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb35f375",
    "outputId": "55344681-580c-49fb-9235-dd460e2c0f91"
   },
   "outputs": [],
   "source": [
    "# extract the time serie for one voxel \n",
    "ts=volume ....\n",
    "# in the AOMICS website find repeat time RT : time in seconds between 2 images in [s]  \n",
    "dt=...\n",
    "# make a vector of slice times in [s]  \n",
    "time_vec= ...# vector \n",
    "print(time_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a7224",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "154a7224",
    "outputId": "6c9184bc-8346-4ac6-f222-38370425dde6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "ax1=plt.subplot(211)\n",
    "# plot the normalaized time serie\n",
    "plt.plot(... , label='bold signal at'+np.array2string(np.array([30,35,30])), linewidth=0.5)\n",
    "plt.ylabel('bold signal')\n",
    "plt.title('bold signal for 1 voxel')\n",
    "\n",
    "plt.subplot(212,  sharex = ax1)\n",
    "# plot the task events as stem of heigth  1\n",
    "plt.stem() \n",
    "# Add title and labels\n",
    "plt.ylabel('stop task events')\n",
    "plt.xlabel('time in [s]')\n",
    "# Add legend\n",
    "plt.legend()\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "# Display plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67c1bf",
   "metadata": {},
   "source": [
    "Now we are going to process the time serie. \n",
    "First we need to load the scipy libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b69771",
   "metadata": {
    "id": "d2b69771"
   },
   "outputs": [],
   "source": [
    "from scipy.fft import fft,fftfreq\n",
    "from scipy.fftpack import fftshift\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d106b7",
   "metadata": {},
   "source": [
    "## First step  is removing complex signal drift\n",
    "For that we are fititng three degree polygone curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dc51a",
   "metadata": {
    "id": "4a3dc51a"
   },
   "outputs": [],
   "source": [
    "# a / fit a 4 degree polynome \n",
    "# find a0, a, b, c, d that fit the signal y= a0 + ax + bx² +cx³ +dx⁴\n",
    "# you can use the code used in the filtering exercice \n",
    "# withoptimize.curve_fit and a test_func \n",
    "# or use numpy.polyfit\n",
    "(...)=np.polyfit(...)\n",
    "drift = \n",
    "\n",
    "# b/ remove the fitted drift from the signa\n",
    "yf=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e477c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "f11e477c",
    "outputId": "7afdfe89-f0f9-4a11-9286-19db5aa771c2"
   },
   "outputs": [],
   "source": [
    "#plotting the whole process\n",
    "t = time_vec\n",
    "y=ts\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "# plot signal and the fitted drift\n",
    "ax2=plt.subplot(411)\n",
    "plt.plot(t, y, 'b-', label='signal')\n",
    "plt.plot(t,drift, 'g--', label='drift')\n",
    "plt.ylabel('bold signal')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# plot  sprectrogram for original signal \n",
    "freqs, times, spectro = spectrogram( y,fs=1/dt, nperseg=3)\n",
    "plt.subplot(412, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.legend()\n",
    "\n",
    "# plot old and new signal (centerd on the mean)\n",
    "plt.subplot(413, sharex=ax2)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, y-y.mean(), label='old bold signal', linewidth=0.5)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, yf-yf.mean(), label='new voxel bold signal', linewidth=2)\n",
    "plt.legend()\n",
    "\n",
    "# plot  sprectrogram for new signal \n",
    "freqs, times, spectro = spectrogram( yf,fs=1/dt, nperseg=3)\n",
    "plt.subplot(414, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.xlabel('t [sec]')\n",
    "plt.legend()\n",
    "\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd05969",
   "metadata": {},
   "source": [
    "Rmoving the drift takes care of very very low frequency noise. \n",
    "But some noise may be still present, let's filter it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488ee10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "b488ee10",
    "outputId": "731b7518-cd1c-495d-ad38-72d09295f48c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make a high pass filter with the code used in the filtering exercice \n",
    "# with cutoff frequecy described in the paper\n",
    "from math import pi\n",
    "import scipy\n",
    "\n",
    "fc =   # desired cutoff frequency of the filter, Hz\n",
    "...\n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "yf_= ...\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1813703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "b1813703",
    "outputId": "b1c941e6-c8ab-4712-aaa6-071e125121cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a low pass filter  with the code use in the filtering exercice\n",
    "# with cutoff frequecy described in the paper\n",
    "fc = ...\n",
    "...\n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "yf_= scipy.signal.filtfilt(b, a, yf)\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb8344",
   "metadata": {},
   "source": [
    "In the nect steps we will try to fit hrf models on our time serie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of hrf model for a gven onset :\n",
    "plt.plot(glm.first_level.spm_hrf(tr=1,onset=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45ed36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we are building the hrf model for all are events\n",
    "# we will use a loop to add \n",
    "# what is the propriety of the convolution that \n",
    "# makes it possible ?\n",
    "\n",
    "import nilearn.glm as glm\n",
    "hrf_mod=  #initialise an empty hrf response vector\n",
    "for ... in ... : # use all events to add hrf to the model\n",
    "    hrf= .... # use  glm.first_level.spm_hrf for an event    \n",
    "    hrf_mod += hrf/sum(hrf) # add it to the model\n",
    "\n",
    "    plt.plot(time_vec,hrf_mod, label=\"model HRF \")\n",
    "plt.ylabel(\"hrf\")\n",
    "plt.xlabel('t [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13309d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy import optimize\n",
    "\n",
    "# Now we will fit our hrf model on the data \n",
    "ts =... # choose a time serie for example\n",
    "\n",
    "# fit an affine model  \n",
    "# find a0, a, signal y= a0 + ax \n",
    "# you can use the code used in the filtering exercice \n",
    "# witho ptimize.curve_fit and a function hrf_model_func\n",
    "def hrf_model_func(...)\n",
    "    ...\n",
    "\n",
    "#for a better optimisation we choose stating parameters\n",
    "p0=...\n",
    "# we run ; optimize.curve_fit with starting parameters\n",
    "params, params_covariance =  optimize.curve_fit(...) \n",
    "\n",
    "# note : you can use polyfit but you don have acces\n",
    "# to covariance parameters (by default)\n",
    "\n",
    "\n",
    "# how do you \n",
    "# ingtrpret parameters \n",
    "# and covriance parameters  ?\n",
    "print(params)\n",
    "print(params_covariance) \n",
    "\n",
    "estimates= ...  # build the estimated hrf response \n",
    "\n",
    "#plotting the results of the original datapoints and the fitted curve\n",
    "plt.plot(time_vec, ts, \"-r\", label = \"Bold signal\")\n",
    "plt.plot(time_vec, estimates, label = \"Fitted hrf serie\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ff178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that implemets all the steps\n",
    "# run it on the  whole volume (you mightskip voxels that are not in the brain !!),  \n",
    "# and make a new image with the result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
